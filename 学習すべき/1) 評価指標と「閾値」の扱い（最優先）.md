- **Accuracy / F1 / AUC / Sens / Spec** がそれぞれ何を意味して、**コンペの採点がどれか**をまず固定。

混合行列：
- **TP (True Positive)**：本当は1、予測も1
    
- **TN (True Negative)**：本当は0、予測も0
    
- **FP (False Positive)**：本当は0、予測が1（誤検知）
    
- **FN (False Negative)**：本当は1、予測が0（見逃し）

## **Accuracy（正解率）**
**全体のうち当たった割合**

$Accuracy=\frac{TP+TN}{TP+TN+FP+FN}$

- クラス不均衡だと「全部0」と予測しても高く出ることがある（罠）。

## **Precision（適合率）※F1の材料**

**“1と予測したもの”のうち本当に1だった割合**

$Precision=\frac{TP}{TP+FP}$

- FP（誤検知）が多いと下がる。
    

  

## **Recall（再現率）＝ Sensitivity（感度）**

  

**“本当に1”をどれだけ拾えたか**

$Recall=\frac{TP}{TP+FN}$

- FN（見逃し）が多いと下がる。
    
- 医療系だと特に重視されやすいことが多い。

## **F1（F1スコア）**

  

**Precision と Recall のバランス（調和平均）**

$F1=\frac{2\cdot Precision\cdot Recall}{Precision+Recall}$

- 「誤検知も見逃しも両方減らしたい」時に使う。
    
- どちらかが極端に低いとF1も低くなる。

## **Sens（Sensitivity：感度）＝ Recall（再現率）**

  

さっきと同じ。

$Sens=\frac{TP}{TP+FN}$

## **Spec（Specificity：特異度）**

  

**“本当に0”をどれだけ0と判定できたか**

Spec=\frac{TN}{TN+FP}

- FP（誤検知）が多いと下がる。
    
- SensとSpecはトレードオフになりがち（閾値で動く）。

## **AUC（ROC-AUC）**

  

**閾値をいろいろ動かしたときの総合的な順位性能（0〜1）**

- ROC曲線：横軸FPR、縦軸TPR
    
    - **TPR = Sens = TP/(TP+FN)**
        
    - **FPR = FP/(FP+TN) = 1 - Spec**
        
    
- **AUCが高いほど「1の画像が0より上に並ぶ」傾向が強い**（確率の“並べ方”が上手い）。
    
- 重要ポイント：
    
    - **AUCは“閾値に依存しない”**（Accuracy/F1/Sens/Specは閾値に依存）
        
    - だから「AUCは高いのにAccuracyが伸びない」＝ **閾値設定が悪い**可能性が高い


- そのうえで
    
    - **確率（sigmoid）→ 閾値で0/1**
        
    - **valで決めた閾値をtestに使う**
        
        を理解する（あなたのコードの find_best_threshold と threshold 更新はここ）。
        
    
- “pred_pos_rateが極端に小さい/大きいとAccが上がるだけ”みたいなことが起きるので、**混同行列で挙動を見る習慣**を最初に作ると最短です。
    


## **あなたのログとの対応（超重要）**

- val_acc(opt)：今の閾値探索で最大化している値（Accuracy）
    
- val_f1(opt)：その閾値でのF1
    
- thr：そのエポックで選ばれた閾値
    
- pred_pos_rate：予測で1にした割合（(TP+FP)/N）
    
- true_pos_rate：正解ラベル1の割合（(TP+FN)/N）
    
- Sens と Spec：混同行列から計算
  

## **2) データ分割・リーク・val/testの前処理（次に最優先）**

- **val/testは“完全に決定的”な変換だけ**（Random系ゼロが基本）。
    
- すでにやった val/test の RandomInvert 削除 は正しい方向。
    
- 次に勉強するのは
    
    - **trainとval/testで何が違うべきか（augmentationの原則）**
        
    - **ROI cropが入ると回転が強すぎて情報が欠ける理由**
        
        の2点。
        
    

  

## **3) 不均衡データの学習（pos_weight / loss / サンプリング）**

- いま BCEWithLogitsLoss(pos_weight=...) を使ってるので、ここを理解すると伸びやすいです。
    
- 勉強ポイント：
    
    - **pos_weightが大きいと「1寄りに予測しやすくなる」**
        
    - その結果、**最適閾値が動きやすい**（あなたのログでもthrが動く）
        
    - 「学習は良いのに提出が伸びない」を潰す鍵になりやすい
        
    

  

## **4) 推論強化（TTA / アンサンブル）を“設計”できるようにする**

- ここは勉強コスパ高いです（学習やり直し無しで上がることがある）。
    
- ただし闇雲に増やすと悪化もあるので、
    
    - **hflipだけ**
        
    - 次に **vflip**
        
    - 次に **rot90**
        
        みたいに**1個ずつ比較する**考え方を身につけるのが重要。
        
    

  

## **5) 実験の進め方（A/Bテストとログの読み方）**

- “飛躍的に上げたい”なら、結局ここが効きます。
    
- 勉強ポイント：
    
    - 変更は**1回に1個**
        
    - 比較は**同じseed/同じsplit/同じepoch**
        
    - 見るのは **val_accだけじゃなく pred_pos_rate・thr・混同行列**
        
    

---

### **今日からの「最短ルート」学習メニュー（超具体）**

1. **混同行列**が読めるようになる（TP/FP/FN/TN）
    
2. **sigmoidと閾値**で何が起きるか説明できるようにする
    
3. **pos_weight**の意味を理解する（なぜpred_pos_rateが動くか）
    
4. **val/testはランダム変換禁止**の理由を理解
    
5. TTAは **hflip→vflip→rot90** を“実験として”回せるようにする
    

  

必要なら、あなたのログ（pred_pos_rate, true_pos_rate, thr, Acc/F1）を見て「次に何を触るべきか」をこちらで1発で優先順位つけるよ。