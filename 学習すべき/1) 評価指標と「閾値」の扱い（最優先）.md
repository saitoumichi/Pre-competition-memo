- **Accuracy / F1 / AUC / Sens / Spec** がそれぞれ何を意味して、**コンペの採点がどれか**をまず固定。
    
- そのうえで
    
    - **確率（sigmoid）→ 閾値で0/1**
        
    - **valで決めた閾値をtestに使う**
        
        を理解する（あなたのコードの find_best_threshold と threshold 更新はここ）。
        
    
- “pred_pos_rateが極端に小さい/大きいとAccが上がるだけ”みたいなことが起きるので、**混同行列で挙動を見る習慣**を最初に作ると最短です。
    

  

## **2) データ分割・リーク・val/testの前処理（次に最優先）**

- **val/testは“完全に決定的”な変換だけ**（Random系ゼロが基本）。
    
- すでにやった val/test の RandomInvert 削除 は正しい方向。
    
- 次に勉強するのは
    
    - **trainとval/testで何が違うべきか（augmentationの原則）**
        
    - **ROI cropが入ると回転が強すぎて情報が欠ける理由**
        
        の2点。
        
    

  

## **3) 不均衡データの学習（pos_weight / loss / サンプリング）**

- いま BCEWithLogitsLoss(pos_weight=...) を使ってるので、ここを理解すると伸びやすいです。
    
- 勉強ポイント：
    
    - **pos_weightが大きいと「1寄りに予測しやすくなる」**
        
    - その結果、**最適閾値が動きやすい**（あなたのログでもthrが動く）
        
    - 「学習は良いのに提出が伸びない」を潰す鍵になりやすい
        
    

  

## **4) 推論強化（TTA / アンサンブル）を“設計”できるようにする**

- ここは勉強コスパ高いです（学習やり直し無しで上がることがある）。
    
- ただし闇雲に増やすと悪化もあるので、
    
    - **hflipだけ**
        
    - 次に **vflip**
        
    - 次に **rot90**
        
        みたいに**1個ずつ比較する**考え方を身につけるのが重要。
        
    

  

## **5) 実験の進め方（A/Bテストとログの読み方）**

- “飛躍的に上げたい”なら、結局ここが効きます。
    
- 勉強ポイント：
    
    - 変更は**1回に1個**
        
    - 比較は**同じseed/同じsplit/同じepoch**
        
    - 見るのは **val_accだけじゃなく pred_pos_rate・thr・混同行列**
        
    

---

### **今日からの「最短ルート」学習メニュー（超具体）**

1. **混同行列**が読めるようになる（TP/FP/FN/TN）
    
2. **sigmoidと閾値**で何が起きるか説明できるようにする
    
3. **pos_weight**の意味を理解する（なぜpred_pos_rateが動くか）
    
4. **val/testはランダム変換禁止**の理由を理解
    
5. TTAは **hflip→vflip→rot90** を“実験として”回せるようにする
    

  

必要なら、あなたのログ（pred_pos_rate, true_pos_rate, thr, Acc/F1）を見て「次に何を触るべきか」をこちらで1発で優先順位つけるよ。