過学習（オーバーフィッティング）しちゃうとどうなるか：
　過学習が起こると「学習データは完璧なのに新しいデータでは全然当たらないモデル」になる
　＝＞一言で言うと「覚えすぎて応用できなくなる」
　学習中の状態：
　・モデルは「このデータを当てること」だけを最優先で学ぶ
　・偶然のノイズ・クセまで記憶する
　＝＞ルールではなく”丸暗記”
数値で見る典型パターン：

| Epoch | 学習精度 | 検証精度 |
| ----- | ---- | ---- |
| 10    | 85%  | 83%  |
| 50    | 99%  | 78%  |
・学習精度：上がり続ける
・検証精度：途中から下がる

直感的に：
試験勉強する際
・過学習：過去問を丸暗記＝＞問題が変わると解けない
・良い学習：原理を理解＝＞初見問題も対応可能

なぜ起こるのか：
主な原因として
・モデルが大きすぎる
　・パラメータが多い
　・表現力が高すぎる
　＝＞小さなデータを全部覚えられる
・データが少ない
　・例が少ない
　・偏りがある
　＝＞偶然のパターンを「本質」と誤解
・学習しすぎ
　・学習を止めるタイミングを逃す

防ぐ方法：
　・データを増やす
　　・一番強い対策
　　・データ拡張（画像回転など）
　・早期終了
　　・検証精度が変わったら止める
　・正則化
　　・L1//L2
　　・重みを大きくしすぎない
　・Dropout
　　・学習中に一部のノードを無効化
　　・丸暗記を防ぐ
　・モデルを小さくする
　　・層・ユニット数を減らす