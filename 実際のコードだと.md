[[改善する点として]]

## **1) しきい値 0.5 をやめて、検証で最適化する（超効くこと多い）**

  

いまは
```
preds = (sigmoid(outputs) >= 0.5)
```

固定だけど、不均衡データだと 0.5 はまず最適じゃない。

- **AUCはそのままでも Accuracy が上がる**ことが普通にある
    
- 目的が「正解率」なら特に効く
    

  

やること：val の y_prob を使って、0.05〜0.95でスキャンして **accuracy最大の閾値**を選ぶ。

---

## **2) Accuracyより「F1」か「balanced accuracy」を最適化（不均衡なら正しい）**

  

今 pos_weight = 1569/806 を入れてるけど、

もし **0が多い/1が少ない**なら accuracy は騙されやすい。

- 0ばっか当てても accuracy は上がる
    
- だから F1 や balanced accuracy を見て調整すると伸びやすい
    

---

## **3) pos_weight の値が逆っぽい（ここ要注意）**

  

pos_weight は「**1の方が少ない時に 1 を重くする**」のが目的。

  

あなたの式：
```
pos_weight_value = 1569 / 806
```

これだと **1569(=多い方?) / 806(=少ない方?)** になっていて、

もし 1569 が「0の枚数」で 806 が「1の枚数」なら OK（1を重くする）。

でも逆なら **悪化**する。

👉 まず train_dataset のラベル数を数えて

- num_pos（ラベル1）
    
- num_neg（ラベル0）
    
    を出して、pos_weight = num_neg / num_pos にするのが基本。
    

---

## **4) 学習率スケジューラを入れる（かなり効く）**

固定 lr=1e-4 だけだと頭打ちになりやすい。

おすすめは簡単で強い：

- ReduceLROnPlateau(val_loss)
    
    → val_loss が止まったら lr を下げる
    
- もしくは CosineAnnealingLR
    

  

これだけで数%伸びることもある。

---

## **5) “最初だけ” backbone を凍結してから解凍（安定して伸びやすい）**

  

ResNet50d を最初から全部学習すると、データが少ない/不均衡だとブレる。

- まず fc（分類層）だけ数epoch学習
    
- その後に全層を解凍して微調整
    

---

## **6) sampler でバランスを取る（pos_weightと併用は注意）**

  

shuffle=True だけだと、ミニバッチ内の偏りが強いことがある。

- WeightedRandomSampler を使うと「毎バッチに1が入りやすい」
    
- ただし **pos_weight と同時に強く効きすぎる**ことがあるので、併用するなら慎重に（どっちか片方から）
    

---

## **7) 画像サイズとCrop戦略を見直す（病理画像系は効くこと多い）**

  

今は 256 -> RandomCrop(224) だけど、

- 病変が小さい/端にあると Crop で消える可能性がある
    

  

候補：

- RandomResizedCrop(224, scale=(0.8,1.0))
    
- あるいは Resize(224)だけで安定させる（上がった経験があるならこっちもアリ）
    

---

## **8) ラベル平滑化 / Focal Loss（最後の手段寄り）**

  

不均衡が強い・難例が多いなら

- Focal Loss が効く場合がある
    
    ただし、まずは上の「閾値」「LR」「freeze」「pos_weight整合」をやった方が再現性高い。
    

---

### **まず最短で試してほしい “次の1手”**

1. **閾値をvalで最適化**（0.5固定をやめる）
    
2. pos_weight が **(neg/pos)** になってるか確認
    
3. ReduceLROnPlateau を入れる
    

  


